import os
from typing import List, Dict
from openai import AsyncOpenAI
import anthropic

LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai").lower()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
ANTHROPIC_MODEL = os.getenv("ANTHROPIC_MODEL", "claude-3-5-sonnet-20240620")

_openai_client = None
_anth_client = None
_chat_history: List[Dict[str, str]] = []

def llm_status() -> str:
    has_oai = bool(os.getenv("OPENAI_API_KEY"))
    has_an = bool(os.getenv("ANTHROPIC_API_KEY"))
    prov = LLM_PROVIDER
    return ("ü§ñ LLM:\n"
            f"‚Ä¢ provider: {prov}\n"
            f"‚Ä¢ openai: {'‚úÖ' if has_oai else '‚ùå'} (model: {OPENAI_MODEL})\n"
            f"‚Ä¢ anthropic: {'‚úÖ' if has_an else '‚ùå'} (model: {ANTHROPIC_MODEL})")

async def _ensure_clients():
    global _openai_client, _anth_client
    if _openai_client is None and os.getenv("OPENAI_API_KEY"):
        _openai_client = AsyncOpenAI()
    if _anth_client is None and os.getenv("ANTHROPIC_API_KEY"):
        _anth_client = anthropic.AsyncAnthropic()

async def ask_once(prompt: str) -> str:
    await _ensure_clients()
    if LLM_PROVIDER == "anthropic" and _anth_client:
        resp = await _anth_client.messages.create(
            model=ANTHROPIC_MODEL, max_tokens=800, temperature=0.3,
            messages=[{"role":"user","content":prompt}]
        )
        return "".join(getattr(block, "text", "") for block in resp.content)
    elif LLM_PROVIDER == "openai" and _openai_client:
        resp = await _openai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role":"system","content":"–¢—ã –∫—Ä–∞—Ç–∫–∏–π, —Ç–æ—á–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                      {"role":"user","content":prompt}],
            temperature=0.3, max_tokens=800
        )
        return resp.choices[0].message.content.strip()
    else:
        return "LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: –ø—Ä–æ–≤–µ—Ä—å –∫–ª—é—á–∏ –∏ LLM_PROVIDER."

async def chat_reply(user_msg: str) -> str:
    await _ensure_clients()
    _chat_history.append({"role":"user","content":user_msg})
    if len(_chat_history) > 24:
        del _chat_history[:len(_chat_history)-24]

    if LLM_PROVIDER == "anthropic" and _anth_client:
        resp = await _anth_client.messages.create(
            model=ANTHROPIC_MODEL, max_tokens=900, temperature=0.6,
            messages=[{"role":m["role"], "content":m["content"]} for m in _chat_history]
        )
        text = "".join(getattr(block, "text", "") for block in resp.content)
    elif LLM_PROVIDER == "openai" and _openai_client:
        msgs = [{"role":"system","content":"–¢—ã –¥–∏–∞–ª–æ–≥–æ–≤—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –ø–æ –¥–µ–ª—É."}] + _chat_history
        resp = await _openai_client.chat.completions.create(
            model=OPENAI_MODEL, messages=msgs, temperature=0.6, max_tokens=900
        )
        text = resp.choices[0].message.content.strip()
    else:
        text = "LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: –ø—Ä–æ–≤–µ—Ä—å –∫–ª—é—á–∏ –∏ LLM_PROVIDER."
    _chat_history.append({"role":"assistant","content":text})
    return text

def reset_chat():
    _chat_history.clear()
